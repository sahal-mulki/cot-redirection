# CoT-Redirection

This repository is the official implementation of **CoT-Redirection**.

| ![An example of CoT-Redirection applied.](https://github.com/sahal-mulki/cot-redirection/blob/1f3a54d1b6e0c84d479ed87cbdb1d145175cf2b5/Picture2.png) | 
|:--:|
| *An example of CoT-Redirection applied.* |

# Table of Contents.
- [Read it!](#read-the-paper!)
- [Table of Contents](#table-of-contents)
- [Abstract](#abstract)
- [Requirements](#requirements)
- [Acknowledgements](#Acknowledgements-and-Award)

# [Read the paper!](https://raw.githubusercontent.com/sahal-mulki/cot-redirection/ad9302b342719bfde539cc09f1b8403464b37976/CoT-Redirection-Final.pdf)

# Abstract

Large Language Models (LLMs) are widely used AI systems that can process and generate high-quality natural language text with contextual understanding. One weakness often presented by LLMs is their lack of common sense and reasoning abilities. Chain of Thought (CoT) is a proposed method to counter this lack of human-like natural reasoning skills. This study explores if it is possible for an attacker to abuse CoT to misalign LLMs and control their responses. Using a secondary review of existing literature, and primary quantitative experiments, this study concludes that it is indeed possible for CoT to be abused for malicious tampering with LLMs. Additionally, this paper contributes to the existing field of adversarial attacks on LLMs, by proposing a novel method for CoT tampering to influence the output of LLMs. This study was limited in its breadth and in the lack of computational resources available. The author of this study hopes that this study will pave the way for further research within the intersection of Chain of Thought and adversarial attacks.

# Requirements

You may also easily use the Google Colab version of the dataset generation notebooks.

### To install dependencies:

`pip install -r requirements.txt`

# Acknowledgements and Award:

I'd like to specially thank Dr. Maheen Hasib from Heriot-Watt University Dubai for her invaluable feedback and mentorship on this paper. Further, I'd like to thank my school, The Westminster School, Dubai, on presenting me with this opportunity.

## Update:

I'm glad to announce that my paper won Best Research Paper in the HW-TWS Action Research Cohort of '25! [More information here.](https://www.linkedin.com/posts/sahalmulki_ai-llm-machinelearning-activity-7338238288173932545-LEq3)

# Cite this:

```
@article{Mulki_2025,
type={Machine Learning},
title={sahal-mulki/cot-redirection},
rights={GPL-3.0},
url={https://github.com/sahal-mulki/cot-redirection},
author={Mulki, Sahal},
year={2025},
month=jun,
language={English}}

```
